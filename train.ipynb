{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962652cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# region 1. Setup Environment & Helper Functions\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, random_split, Subset, WeightedRandomSampler\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.models import EfficientNet_V2_L_Weights\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --- HARDWARE SETUP (Silent Optimization) ---\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Logika presisi tetap berjalan di background, tapi tidak di-print ke user\n",
    "if hasattr(torch, 'float8_e4m3fn') and DEVICE.type == 'cuda':\n",
    "    AMP_DTYPE = torch.float8_e4m3fn \n",
    "    USE_SCALER = False \n",
    "elif torch.cuda.is_bf16_supported():\n",
    "    AMP_DTYPE = torch.bfloat16\n",
    "    USE_SCALER = False\n",
    "else:\n",
    "    AMP_DTYPE = torch.float16\n",
    "    USE_SCALER = True\n",
    "\n",
    "print(f\"Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
    "\n",
    "class CheckpointWrapper(nn.Module):\n",
    "    def __init__(self, module):\n",
    "        super().__init__()\n",
    "        self.module = module\n",
    "    def forward(self, x):\n",
    "        return checkpoint(self.module, x, use_reentrant=False)\n",
    "\n",
    "class TransformedSubset(torch.utils.data.Dataset):\n",
    "    def __init__(self, subset, transform):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.subset[index]\n",
    "        if self.transform: x = self.transform(x)\n",
    "        return x, y\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, dataloaders, device, num_epochs, dataset_sizes, phase_name=\"Training\"): \n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    \n",
    "    scaler = torch.amp.GradScaler('cuda') if USE_SCALER else None\n",
    "\n",
    "    print(f\"\\n--- Memulai {phase_name} ({num_epochs} Epochs) ---\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        for phase in ['train', 'val']:\n",
    "            model.train() if phase == 'train' else model.eval()\n",
    "            running_loss, running_corrects = 0.0, 0\n",
    "            \n",
    "            # Progress bar bersih\n",
    "            pbar = tqdm(dataloaders[phase], desc=f\"{phase.capitalize()}\", leave=False)\n",
    "\n",
    "            for inputs, labels in pbar:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Autocast berjalan silent sesuai kemampuan hardware\n",
    "                with torch.set_grad_enabled(phase == 'train'), \\\n",
    "                     torch.autocast(device_type=device.type, dtype=AMP_DTYPE, enabled=(device.type == 'cuda')): \n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    if scaler:\n",
    "                        scaler.scale(loss).backward()\n",
    "                        scaler.step(optimizer)\n",
    "                        scaler.update()\n",
    "                    else:\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                # Update progress bar dengan metrics real-time\n",
    "                pbar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f'{torch.sum(preds == labels.data)/inputs.size(0):.4f}'})\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            print(f\"  {phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "            if phase == 'train':\n",
    "                history['train_loss'].append(epoch_loss)\n",
    "                history['train_acc'].append(epoch_acc.item())\n",
    "            else:\n",
    "                history['val_loss'].append(epoch_loss)\n",
    "                history['val_acc'].append(epoch_acc.item())\n",
    "                if epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    torch.save(model.state_dict(), f'best_model_{phase_name.replace(\" \", \"_\").lower()}_temp.pth')\n",
    "        \n",
    "        if scheduler: scheduler.step()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f\"Selesai: {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s | Best Acc: {best_acc:.4f}\")\n",
    "    try: model.load_state_dict(best_model_wts)\n",
    "    except: pass\n",
    "    return model, history\n",
    "# endregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9f337c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# region 2. Config & Data Loading\n",
    "DATASET_PATH = 'Dataset'\n",
    "IMG_SIZE = 224\n",
    "\n",
    "# Batch Size (Sesuaikan jika OOM)\n",
    "BATCH_SIZE_EXTRACT = 64  \n",
    "BATCH_SIZE_TUNE = 8      \n",
    "    \n",
    "EPOCHS_FEATURE_EXTRACT = 10\n",
    "EPOCHS_FINE_TUNE = 20\n",
    "    \n",
    "VALIDATION_SPLIT = 0.2 \n",
    "LR_FEATURE_EXTRACT = 1e-2\n",
    "LR_FINE_TUNE = 1e-3\n",
    "WEIGHT_DECAY = 1e-2\n",
    "LABEL_SMOOTHING = 0.1\n",
    "    \n",
    "PLOT_FILENAME = 'training_results.png'\n",
    "CONFUSION_MATRIX_FILENAME = 'confusion_matrix.png'\n",
    "BEST_MODEL_EXTRACT_PATH = 'best_model_extract.pth'\n",
    "MODEL_SAVE_PATH = 'citrus_efficientnetv2l_final.pth'\n",
    "\n",
    "print(\"Mempersiapkan Data...\")\n",
    "weights = EfficientNet_V2_L_Weights.DEFAULT\n",
    "preprocess = weights.transforms(antialias=True)\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE + 32),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    preprocess\n",
    "])\n",
    "val_transforms = preprocess\n",
    "\n",
    "try:\n",
    "    full_dataset = datasets.ImageFolder(DATASET_PATH, transform=None)\n",
    "    CLASSES = sorted(full_dataset.classes)\n",
    "    NUM_CLASSES = len(CLASSES)\n",
    "    print(f\"Dataset: {len(full_dataset)} images | {NUM_CLASSES} classes\")\n",
    "\n",
    "    class_counts = np.bincount(full_dataset.targets)\n",
    "    class_weights = [len(full_dataset) / c for c in class_counts]\n",
    "    \n",
    "    train_size = int((1 - VALIDATION_SPLIT) * len(full_dataset))\n",
    "    val_size = len(full_dataset) - train_size\n",
    "    train_indices, val_indices = random_split(range(len(full_dataset)), [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "    train_targets = [full_dataset.targets[i] for i in train_indices]\n",
    "    sample_weights = [class_weights[t] for t in train_targets]\n",
    "    sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(train_indices), replacement=True)\n",
    "\n",
    "    train_dataset = TransformedSubset(Subset(full_dataset, train_indices), train_transforms)\n",
    "    val_dataset = TransformedSubset(Subset(full_dataset, val_indices), val_transforms)\n",
    "\n",
    "    num_workers = 0 \n",
    "    \n",
    "    dataloaders_extract = {\n",
    "        'train': DataLoader(train_dataset, batch_size=BATCH_SIZE_EXTRACT, sampler=sampler, num_workers=num_workers, pin_memory=True),\n",
    "        'val': DataLoader(val_dataset, batch_size=BATCH_SIZE_EXTRACT, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "    }\n",
    "    dataloaders_tune = {\n",
    "        'train': DataLoader(train_dataset, batch_size=BATCH_SIZE_TUNE, sampler=sampler, num_workers=num_workers, pin_memory=True),\n",
    "        'val': DataLoader(val_dataset, batch_size=BATCH_SIZE_TUNE, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "    }\n",
    "    dataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset)}\n",
    "    class_names = CLASSES\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error Dataset: {e}\")\n",
    "    sys.exit(1)\n",
    "# endregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9acedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# region 3. Feature Extraction\n",
    "print(\"\\n=== TAHAP 1: FEATURE EXTRACTION ===\")\n",
    "model_extract = models.efficientnet_v2_l(weights=weights)\n",
    "\n",
    "# Manual Gradient Checkpointing\n",
    "for i in range(len(model_extract.features)):\n",
    "    model_extract.features[i] = CheckpointWrapper(model_extract.features[i])\n",
    "\n",
    "# Freeze Backbone\n",
    "for param in model_extract.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_ftrs = model_extract.classifier[1].in_features\n",
    "model_extract.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.4, inplace=True),\n",
    "    nn.Linear(num_ftrs, NUM_CLASSES)\n",
    ")\n",
    "model_extract = model_extract.to(DEVICE)\n",
    "\n",
    "criterion_extract = nn.CrossEntropyLoss(label_smoothing=LABEL_SMOOTHING)\n",
    "optimizer_extract = optim.AdamW(model_extract.classifier.parameters(), lr=LR_FEATURE_EXTRACT, weight_decay=WEIGHT_DECAY)\n",
    "scheduler_extract = optim.lr_scheduler.CosineAnnealingLR(optimizer_extract, T_max=EPOCHS_FEATURE_EXTRACT)\n",
    "\n",
    "model_extract, history_extract = train_model(\n",
    "    model_extract, criterion_extract, optimizer_extract, scheduler_extract, dataloaders_extract, DEVICE, \n",
    "    EPOCHS_FEATURE_EXTRACT, dataset_sizes, phase_name=\"Feature Extraction\"\n",
    ")\n",
    "\n",
    "torch.save(model_extract.state_dict(), BEST_MODEL_EXTRACT_PATH)\n",
    "# endregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e55c832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# region 4. Fine Tuning\n",
    "print(\"\\n=== TAHAP 2: FINE-TUNING ===\")\n",
    "model_tune = models.efficientnet_v2_l(weights=None) \n",
    "num_ftrs_tune = model_tune.classifier[1].in_features\n",
    "model_tune.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.4, inplace=True),\n",
    "    nn.Linear(num_ftrs_tune, NUM_CLASSES)\n",
    ")\n",
    "\n",
    "# Re-apply Checkpointing\n",
    "for i in range(len(model_tune.features)):\n",
    "    model_tune.features[i] = CheckpointWrapper(model_tune.features[i])\n",
    "\n",
    "try:\n",
    "    model_tune.load_state_dict(torch.load(BEST_MODEL_EXTRACT_PATH, map_location='cpu'))\n",
    "    print(\"Bobot dimuat.\")\n",
    "except:\n",
    "    model_tune.load_state_dict(model_extract.state_dict())\n",
    "\n",
    "# Unfreeze All Layers\n",
    "for param in model_tune.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "model_tune = model_tune.to(DEVICE)\n",
    "\n",
    "optimizer_tune = optim.AdamW(model_tune.parameters(), lr=LR_FINE_TUNE, weight_decay=WEIGHT_DECAY)\n",
    "scheduler_tune = optim.lr_scheduler.CosineAnnealingLR(optimizer_tune, T_max=EPOCHS_FINE_TUNE)\n",
    "\n",
    "model_final, history_tune = train_model(\n",
    "    model_tune, criterion_extract, optimizer_tune, scheduler_tune, dataloaders_tune, DEVICE, \n",
    "    EPOCHS_FINE_TUNE, dataset_sizes, phase_name=\"Fine-Tuning\"\n",
    ")\n",
    "\n",
    "# Merge History\n",
    "combined_history = {}\n",
    "if 'history_extract' in locals():\n",
    "    combined_history['train_loss'] = history_extract.get('train_loss', []) + history_tune.get('train_loss', [])\n",
    "    combined_history['train_acc'] = history_extract.get('train_acc', []) + history_tune.get('train_acc', [])\n",
    "    combined_history['val_loss'] = history_extract.get('val_loss', []) + history_tune.get('val_loss', [])\n",
    "    combined_history['val_acc'] = history_extract.get('val_acc', []) + history_tune.get('val_acc', [])\n",
    "\n",
    "torch.save(model_final.state_dict(), MODEL_SAVE_PATH)\n",
    "print(f\"Model tersimpan: {MODEL_SAVE_PATH}\")\n",
    "# endregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b5099d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# region 5. Visualization & Evaluation\n",
    "print(f\"\\nMembuat Visualisasi...\")\n",
    "if combined_history and combined_history.get('train_acc'):\n",
    "    acc = combined_history['train_acc']\n",
    "    val_acc = combined_history['val_acc']\n",
    "    loss = combined_history['train_loss']\n",
    "    val_loss = combined_history['val_loss']\n",
    "    epochs_range = range(1, len(acc) + 1)\n",
    "    \n",
    "    plt.figure(figsize=(14, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Train Acc')\n",
    "    plt.plot(epochs_range, val_acc, label='Val Acc')\n",
    "    if 'history_extract' in locals():\n",
    "         plt.axvline(len(history_extract['train_acc']) + 0.5, color='grey', linestyle='--', label='Fine-Tuning Start')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Accuracy')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Train Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Val Loss')\n",
    "    if 'history_extract' in locals():\n",
    "         plt.axvline(len(history_extract['train_acc']) + 0.5, color='grey', linestyle='--', label='Fine-Tuning Start')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Loss')\n",
    "\n",
    "    plt.savefig(PLOT_FILENAME)\n",
    "    plt.show()\n",
    "\n",
    "print(f\"\\nMembuat Confusion Matrix...\")\n",
    "if 'model_final' in locals():\n",
    "     model_final.eval()\n",
    "     all_preds, all_labels = [], []\n",
    "     \n",
    "     with torch.no_grad():\n",
    "         for inputs, labels in tqdm(dataloaders_tune['val'], desc=\"Evaluasi\"):\n",
    "             inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "             \n",
    "             with torch.autocast(device_type=DEVICE.type, dtype=AMP_DTYPE, enabled=(DEVICE.type == 'cuda')):\n",
    "                outputs = model_final(inputs)\n",
    "                \n",
    "             _, preds = torch.max(outputs, 1)\n",
    "             all_preds.extend(preds.cpu().numpy())\n",
    "             all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "     cf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "     plt.figure(figsize=(10, 8))\n",
    "     sns.heatmap(cf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "     plt.ylabel('True Label')\n",
    "     plt.xlabel('Predicted Label')\n",
    "     plt.tight_layout()\n",
    "     plt.savefig(CONFUSION_MATRIX_FILENAME)\n",
    "     plt.show()\n",
    "\n",
    "print(\"\\n--- Selesai ---\")\n",
    "# endregion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
